# -*- coding: utf-8 -*-
"""Twitter Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wjz7kgAA3nmncRfP595e6miZXqQKCZiI

# **Importing the Necessary Packages**
"""

import pandas as pd #Pandas for DataFrame Actions
import numpy as np #Numpy for Arithmetic Calculation
import matplotlib.pyplot as plt
from datetime import date
from textblob import TextBlob

"""# **Conversion of CSV file to DataFrame**"""

a='https://raw.githubusercontent.com/Manikandan-professional/Datasets/main/tweets.csv'

df=pd.DataFrame(pd.read_csv(a))
df.head()

"""# **Number of Rows and Columns**"""

df.shape

"""# **Old and New Columns value and renaming**"""

old=[]
new=[]
for i in range(0,len(df.columns),1):
  old.append(df.columns[i])
for i in range(0,df.shape[1],1):
  new.append(df.iloc[0][i])
for i in range(0,df.shape[1],1):
  df=df.rename(columns={old[i]:new[i]})

df.head(2)

"""# **Removing the first row since we have renamed it with column value**"""

df=df.drop(df.index[0],axis=0)

df.head()

df.columns

df=df.drop(columns=['Full Name','Screen Name','Tweet ID','Link(s)','Media','Media', 'Location', 'Retweets', 'Favorites', 'App', 'Followers',
       'Follows', 'Listed', 'Verfied', 'User Since', 'Location', 'Bio',
       'Website', 'Timezone', 'Profile Image'])

"""# **Final Dataset which is going to use for our analysis**"""

df.head()
df=df.reset_index()

"""# **Data Cleaning**"""

df=df.dropna()

df

df=df.drop(columns=['index'])

for i in range(0,df.shape[0],1):
  df['Tweet Text'][i]=df['Tweet Text'][i].lower()

df

"""# **Splitting of Date and Time**"""

df['Year']=""

df['Date'][0][0:10]

for i in range(0,df.shape[0],1):
  df['Year'][i]=df['Date'][i][6:10]

df.head()

df['Tweet Text'][0]

df['subjectivity']=0.0
df['polarity']=0.0

df.head(1)

a=TextBlob(df['Tweet Text'][1])
a.sentiment

p=[]
s=[]

for i in range(0,df.shape[0],1):
  # w = df['Tweet Text'][i]
  # w.lemmatize("v") ## v here represents verb
  text=TextBlob(df['Tweet Text'][i])
  p.append(text.sentiment[0])
  s.append(text.sentiment[1])
  df['polarity'][i]=p[i]
  df['subjectivity'][i]=s[i]

df.head(20)

plt.scatter(df.index,df.polarity)

!pip install vaderSentiment

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

analyzer = SentimentIntensityAnalyzer()

sentiment = df['Tweet Text'].apply(analyzer.polarity_scores)

sentiment_df = pd.DataFrame(sentiment.tolist())

sentiment_df.head()

final = pd.concat([df,sentiment_df], join = 'outer', axis = 1)
final

final=final.rename(columns={'neg':'Negative','neu':'Neutral','pos':'Positive','compound':'compound'})
final.head()

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
STOPWORDS = set(stopwords.words('english'))

total=final.shape[0]
neg=final['Negative'].sum()
neu=final['Neutral'].sum()
pos=final['Positive'].sum()
print('Negative Average',round((neg/total)*100,2))
print('Neutral Average',round((neu/total)*100,2))
print('Positive Average',round((pos/total)*100,2))

finals=pd.DataFrame(final[['Tweet Text',	'Neutral']])
#,'subjectivity'	,'polarity',	'Negative'	,'Positive',

finals.head()

finals['Neutral'].min()

for i in range(0,df.shape[0],1):
  if finals['Neutral'][i]>0.50:
    finals['Neutral'][i]=1
  else:
    finals['Neutral'][i]=0

finals.shape[0]*70/100

